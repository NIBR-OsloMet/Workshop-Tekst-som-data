---
title: "TM og STM"
author: "Yuri Kasahara"
date: "2024-03-12"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
    theme: cerulean
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Topic Modelling og Structural Topic Modelling

## Hva er de?

Topic modelling er en form for uveiledet maskinlæring som brukes til å oppdage de skjulte tematiske strukturene i store tekstkorpora. Metoden analyserer samlingene av tekster for å identifisere gjentagende mønstre av ord som representerer temaer. I stedet for å kreve forhåndsdefinerte kategorier eller etiketter, oppdager topic modelling statistiske grupperinger av ord (og dermed "topics") som fremkommer fra korpora selv. Dette gjør metoden særlig nyttig for å utforske store tekstuelle datasett hvor de underliggende tematiske strukturene ikke er kjent på forhånd. De mest kjente algoritmene for topic modelling inkluderer Latent Dirichlet Allocation (LDA) og Non-negative Matrix Factorization (NMF). Tema-modellering har blitt anvendt i en rekke felt, fra digital humaniora til markedsforskning, for å avdekke innsikt i store tekstuelle data som ikke lett lar seg observere gjennom manuell gjennomgang.

Structural Topic Modelling er en variant av Topic Modelling som benyttes av metadata koblet til teksten. I utgangspunkt, bruker ikke vanlig LDA eller NMF informasjon som vi kan ha om tekster/korpora. Informasjon som forfatter, dato av publisering og forlag brukes aktivt i estimeringen av temaer ved å bruke STM.

## Viktig å vite

-   Topic modelling trenger et antall temaer som skal organiseres på forhånd. Det finnes ikke et "riktig" antall av temaer.
-   Temaer gir ikke nødvendigvis mening. Forsker må alltid sjekke de genererte temaer for å se om de gir mening.
-   De fleste TM algoritmer er sannsynlighetsbasert. Huske å "seed" din modellen for å sikre at det kan repliseres.

## Intuisjon bak LDA og andre sannsynlighetsbasert topic models

-   Dokumenter er sannsynlighetsfordelinger av latente variabler (topics).
-   Topics er sannsynlighetsfordelinger av ord.
-   Hver dokument har et bestemt antall temaer.
-   LDA og varianter bruker "bag of words" tilnærming til tekst - ikke hensyn til kontekst.

```{r echo = FALSE, out.width="100%", fig.cap="Source: Blei, D. M. (2012), Probabilistic Topic Models"}
knitr::include_graphics("C:/Users/yurik/OneDrive - OsloMet/Dokumenter/AI Lab/Digital Social Sciences/STM/blei_ptm.webp")

```

# Biblioteker og data vi skal bruke

```{r, error=FALSE, warning=FALSE, message=FALSE, echo=TRUE, results='hide'}
library(tm)
library(topicmodels)
library(stm)
library(tidyverse)
library(quanteda)
library(stopwords)
library(tidytext)
```

```{r, echo=TRUE}

info_reports_SVA_with_lang <- read.csv("info_reports_SVA_with_lang.csv", encoding = "UTF-8")


```

```{r, echo=FALSE}
knitr::kable(info_reports_SVA_with_lang[1:2, ], caption = "Data burde ser som ut.")

```

# Prossesering av tekster

La oss beholde bare sammendrag på norsk og nynorsk

```{r, error=FALSE, warning=FALSE, message=FALSE, echo=TRUE, results='hide'}

info_reports_SVA_no <- info_reports_SVA_with_lang %>% filter(info_reports_SVA_with_lang$doc_lang == "no" |    info_reports_SVA_with_lang$doc_lang == "nn")


```

La oss forvandle variabler type for bedre behandling

```{r, error=FALSE, warning=FALSE, message=FALSE, echo=TRUE, results='hide'}


info_reports_SVA_no$Institute <- as.factor(info_reports_SVA_no$Institute)
info_reports_SVA_no$Year <- as.numeric(info_reports_SVA_no$Year)


```

La oss bruke quanteda for å lage vår korpora fil.

```{r, error=FALSE, warning=FALSE, message=FALSE, echo=TRUE, results='hide'}

SVA_corpus <- corpus(info_reports_SVA_no, text_field="Abstract")

summary(SVA_corpus)

```

Vi trenger å lage en "document-feature matrix" for å kjøre en topic model!

```{r, error=FALSE, warning=FALSE, message=FALSE, echo=TRUE, results='markup'}

# Ved å bruke dfm funksjon kan vi fjerne andre symboler og ordene som ikke er nyttige
SVA_corpus_dfm <- dfm(SVA_corpus, remove_numbers=TRUE, remove_punct=TRUE, remove_symbols=TRUE, remove = c(stopwords("no"), stopwords("en")))

SVA_corpus_dfm

```

Vi kan redusere vår DFM ved å slette mest/minst frekvent ord.

```{r, error=FALSE, warning=FALSE, message=FALSE, echo=TRUE, results='markup'}

SVA_corpus_dfm.trim <- dfm_trim(SVA_corpus_dfm, min_termfreq = 2, max_termfreq = 75)

SVA_corpus_dfm.trim

```

# Enkel Topic Model med LDA

Nå skal vi trene en modell.

```{r, error=FALSE, warning=FALSE, message=FALSE, echo=TRUE, results='markup'}

# Antall temaer må defineres
n_topics <- 4

# Forvandle matrisen til en LDA format
dfm2topicmodel <- convert(SVA_corpus_dfm.trim, to="topicmodels")

# Kjøre modellen. Det kan ta tid avhengig av hvor mange temaer du kjører.
lda.model <- LDA(dfm2topicmodel, n_topics, control = list(seed=1710249719))

#La oss visualisere ordene per tema
model_topics <- as.data.frame(terms(lda.model, 4))

# På en bedre måte

model_topics <- tidy(lda.model, matrix = "beta")
model_topics

top_terms <- model_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>% 
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()
```

Vi kan også sjekke fordelling av dokumenter per tema.

```{r}

#Ta gamma values fra lda.model outuput

gamma_values <- as.data.frame(lda.model@gamma)

# Få bare den høyeste gamma verdi per dokument
max_topic_per_document <- apply(gamma_values, 1, which.max)

# Lage en dataset med telling av dokumenter per topic
topic_counts <- as.data.frame(table(MaxTopic = max_topic_per_document))

# La oss lage en figur for å se
ggplot(topic_counts, aes(x = MaxTopic, y = Freq)) +
  geom_bar(stat = "identity", fill = "blue") +
  theme_minimal() +
  labs(title = "Number of Documents in Each Topic",
       x = "Topic",
       y = "Number of Documents") 
  
```

Vi kan også se resultater for enkel dokument

```{r}


topics_dokumenter <- tidy(lda.model, matrix = "gamma")
topics_dokumenter

#fordelinger av temaer på text1
topics_dokumenter %>% filter(document == "text1") %>%
  arrange(desc(gamma))
 
#Vi kan se også de ordene i den dokumenten
tidy(SVA_corpus_dfm.trim) %>%
  filter(document == "text1") %>%
  arrange(desc(count))

```

## Men hvordan kan vi si at vi har en god modell?

```{r}
train = sample(rownames(dfm2topicmodel), nrow(dfm2topicmodel) * .75)
dtm_train = dfm2topicmodel[rownames(dfm2topicmodel) %in% train, ]
dtm_test = dfm2topicmodel[!rownames(dfm2topicmodel) %in% train, ]

m = LDA(dtm_train, method = "Gibbs", k = 5,  control = list(alpha = 0.01))

perplexity(m, dtm_test)

```

Men vi trenger flere målinger for å vite hvor godt den modellen er.

```{r}
## Lage en datasett for å lagre "perplexity scores" for forskjellige verdier av k
p = data.frame(k = c(2,4,8,16,32,64,128), perplexity = NA)

## "loop" over k verdier i datasett p 
for (i in 1:nrow(p)) {
  print(p$k[i])
  ## beregne perplexity for hver k verdi
  m = LDA(dtm_train, method = "Gibbs", k = p$k[i],  control = list(alpha = 0.01))
  ## lagre resultater i datasett p
  p$perplexity[i] = perplexity(m, dtm_test)
}
```

Nå kan vi visualisere resultatene

```{r}
ggplot(p, aes(x=k, y=perplexity)) + geom_line()

```

Kanskje 16 er noe bedre?

# Structural Topic Model (STM)

Vi bruker samme logikk for å bygge opp en LDA model. Største fordel er at STM bibliotek har mange innbygde funksjoner i seg.

```{r, echo=TRUE}
# Prossesering av tekst er en del enklere for bygge opp vår Document-Term Matrix

info_reports_SVA_no <- info_reports_SVA_no[c('Abstract', 'Institute', 'Year')]


extra_words <- c("the", "that", "and", "this", "are", "more", "has", "than",
                 "with", "also", "have", "has", "been", "from", "their", "derfor",
                 "eksempel")

info_reports.proc <- textProcessor(documents=info_reports_SVA_no$Abstract,
                                 metadata = info_reports_SVA_no,
                                 lowercase = TRUE, #*
                                 removestopwords = TRUE, #*
                                 removenumbers = TRUE, #*
                                 removepunctuation = TRUE, #*
                                 stem = TRUE, #*
                                 wordLengths = c(3,Inf), #*
                                 sparselevel = 1, #*
                                 language = "no", #*
                                 verbose = TRUE, #*
                                 onlycharacter = TRUE, # 
                                 striphtml = FALSE, #*
                                 customstopwords = extra_words, #*
                                 v1 = FALSE) #*


```

Nå trenger vi må prossesere korpora for å kjøre en STM.

```{r}

#Vi kan fjerne de mest/minst frekvente ordene basert på hvor ofte er de på dokumentene

processed_reports <- prepDocuments(info_reports.proc$documents, info_reports.proc$vocab, info_reports.proc$meta, lower.thresh = 2, upper.thresh = 100)

docs <- processed_reports$documents
vocab <- processed_reports$vocab
meta <- processed_reports$meta

```

Vi kan se hvor mange dokumenter skal fjernes basert på forskjellige "tresholds".

```{r eval=FALSE, include=FALSE}

plotRemoved(processed_reports$documents, lower.thresh=seq(1,200, by=100))
```

I STM bibliotek har vi en funksjon som analysere forskjellige målstøkke for å prøve å finne den beste antall temaer for å modellere. Men huske å gi en spesifikasjon av hvordan meta-variabler påvirke temaer. Dette kan ta veldig lang tid!

```{r, results='hide'}

storage <- searchK(processed_reports$documents, processed_reports$vocab, K = c(2:50), prevalence=~Year+Institute, data = processed_reports$meta, heldout.seed = 1234)
```

Vi kan se resultatene

```{r}
plot.searchK(storage)
```

La oss kjøre en modell med 10 temaer

```{r}
InfoSVAPrevFit <- stm(processed_reports$documents, processed_reports$vocab, K=10, prevalence=~s(Year)+Institute, content =~ Institute, max.em.its=100, data=processed_reports$meta, init.type="Spectral", seed=1234)
```

Vi kan lage en figur for å vise hvor omfattende er hver tema

```{r}
plot(InfoSVAPrevFit, type="summary", xlim=c(0,.6))
```

La oss se hoved ordene av hvert temaet

```{r}
plot(InfoSVAPrevFit, type="labels", topics=c(1:10))
```

Nå kan vi estimere effekter av meta-variabler over temaer

```{r}
model <- estimateEffect(1:10 ~ Year + Institute, InfoSVAPrevFit, meta = processed_reports$meta, uncertainty = "Global")

summary(model, topics = c(1:5))

```

Vi kan lage figurer for å visualisere effekter av variabler over hver tema

```{r}
#For institute
plot.estimateEffect(model, covariate = "Institute", topics = c(3),
 model = InfoSVAPrevFit, method = "pointestimate",
 xlab = "Marginal topic proportion for each level",
 main = "Effect of Institute", xlim = c(-0.1, 0.6),
)

#For Year

plot(model, "Year", method = "continuous", topics = 3, printlegend = FALSE, xaxt = "n", xlab = "Year")

```

Vi kan se kort deler av dokumentene som mest identifiserte med et tema.

```{r}
short_abstract <- substr(meta$Abstract, start = 1, stop = 180)

example_docs <- findThoughts(InfoSVAPrevFit, texts = short_abstract, n=4, topics=3)

plotQuote(example_docs$docs[[1]])

```

Vi kan også se hvilken ord er mest knyttede til hvert institutt i hvert temaet.

```{r}

plot(InfoSVAPrevFit, type = "perspectives", covarlevels = c('AFI', 'SIFO'), topics = 3)

plot(InfoSVAPrevFit, type = "perspectives", covarlevels = c('NIBR', 'NOVA'), topics = 3)

```
