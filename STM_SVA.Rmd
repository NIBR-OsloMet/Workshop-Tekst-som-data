---
title: "Structural Topic Model - R"
format: pptx
editor: visual
---

## What is it?

It is a probabilistic topic model like latent Dirichlet allocation (LDA). The main innovation is to incorporate metadata about each document into the model. Recommended when you have additional information about the documents forming your corpus.

In R, the package STM provides a good and user-friendly implementation of the model.

## Let's apply it to our collected data!

```{r}
library(stm)
library(tidyverse)
```

## First step: process the text material

```{r}
info_reports_SVA_with_lang <- read.csv("info_reports_SVA_with_lang.csv")

# select only abstracts in Norwegian

info_reports_SVA_no <- info_reports_SVA_with_lang %>% filter(info_reports_SVA_with_lang$doc_lang == "no" | info_reports_SVA_with_lang$doc_lang == "nn")

info_reports_SVA_no$Institute <- as.factor(info_reports_SVA_no$Institute)
info_reports_SVA_no$Year <- as.numeric(info_reports_SVA_no$Year)


info_reports_SVA_no <- info_reports_SVA_no[c('Abstract', 'Institute', 'Year')]


extra_words <- c("the", "that", "and", "this", "are", "more", "has", "than",
                 "with", "also", "have", "has", "been", "from", "their", "derfor",
                 "eksempel")

info_reports.proc <- textProcessor(documents=info_reports_SVA_no$Abstract,
                                 metadata = info_reports_SVA_no,
                                 lowercase = TRUE, #*
                                 removestopwords = TRUE, #*
                                 removenumbers = TRUE, #*
                                 removepunctuation = TRUE, #*
                                 stem = TRUE, #*
                                 wordLengths = c(3,Inf), #*
                                 sparselevel = 1, #*
                                 language = "no", #*
                                 verbose = TRUE, #*
                                 onlycharacter = TRUE, # not def
                                 striphtml = FALSE, #*
                                 customstopwords = extra_words, #*
                                 v1 = FALSE) #*
```

## Let's remove words that are appear too little and too often.

```{r}
processed_reports <- prepDocuments(info_reports.proc$documents, info_reports.proc$vocab, info_reports.proc$meta, lower.thresh = 5, upper.thresh = 150)

docs <- processed_reports$documents
vocab <- processed_reports$vocab
meta <- processed_reports$meta
```

## You can check visually how many documents you will exclude based on different tresholds

```{r}
plotRemoved(processed_reports$documents, lower.thresh=seq(1,200, by=150))
```

## In a topic model, the number of topics (k) is assigned arbitraly by the researcher. We can run some tests to have an idea of what is the best number. Let's run different metrics for k between 5 and 40 topics.

```{r}
storage <- searchK(processed_reports$documents, processed_reports$vocab, K = c(5:40), prevalence=~Year+Institute, data = processed_reports$meta)

```

## Let's see the metrics

```{r}
plot.searchK(storage)
```

## 

Let's fit the model setting k = 6.

```{r}
InfoSVAPrevFit <- stm(processed_reports$documents, processed_reports$vocab, K=6, prevalence=~s(Year)+Institute, max.em.its=100, data=processed_reports$meta, init.type="Spectral", seed=8458159)
```

## 

Let's investigate our topics (distribution of tokens/topic)

```{r}
plot(InfoSVAPrevFit, type="summary", xlim=c(0,.8))
```

## Most common words associated with each topic

```{r}
plot(InfoSVAPrevFit, type="labels", topics=c(1:6), text.cex = 0.8)
```

## We can also plot excerpts of the documents in each topic

```{r}
short_abstract <- substr(meta$Abstract, start = 1, stop = 180)

example_docs <- findThoughts(InfoSVAPrevFit, texts = short_abstract, n=4, topics=1)

plotQuote(example_docs$docs[[1]])
```

## We can also plot word clouds for each topic

```{r}

cloud(InfoSVAPrevFit, topic = 4, scale = c(2, 0.25))

```

## We can plot a figure showing the correlation between topics

```{r}
mod.out.corr <- topicCorr(InfoSVAPrevFit, method = "huge")

plot(mod.out.corr)

```

```{r}

model <- estimateEffect(1:6 ~ Year + Institute, InfoSVAPrevFit, meta = processed_reports$meta, uncertainty = "Global")

summary(model, topics = c(1:6))

```


## We can check the effect of variables on each topic. For prevalence:

```{r}
plot.estimateEffect(model, covariate = "Institute", topics = c(3),
 method = "pointestimate",
 xlab = "Marginal topic proportion for each level",
 main = "Effect of Institute", xlim = c(-0.1, 0.6),
)
```

```{r}
plot.estimateEffect(model, covariate = "Year", topics = 4,
 method = "continuous",
 model = InfoSVAPrevFit,
 xlab = "Years"
 )
```












